
# 1.1 人工智能，机器学习，神经网络和深度学习

像“人工智能”、机器学习、神经网络和深度学习这样的短语意味着相关但不同的东西。你需要了解它们分别指的是什么，接下来让我们来定义这些术语以及它们之间的关系。

###### 图1.1 人工智能、机器学习、神经网络与深度学习的关系。如图所示，机器学习是人工智能的一个子领域。人工智能的某些领域使用了不同于机器学习的方法。神经网络是机器学习的一个分支。存在非神经网络机器学习技术，如决策树。深度学习是创造和应用“深度”神经网络的科学和艺术，即多“层”神经网络，这是相对于“浅层”神经网络，即层次少的神经网络而言的。
 
<img :src="$withBase('/introduction/1.png')" alt="figure1"/>

## 1.1.1 人工智能
如图1所示，人工智能是一个广阔的领域。该领域的简明定义如下：自动进行通常由人类完成的智力任务。
因此，人工智能是一个广泛的领域，包括机器学习、神经网络和深度学习，但也包括许多不同于机器学习的方法。例如，早期的国际象棋程序涉及由程序员编制的硬编码规则。这些不符合机器学习的条件，他们使用明确的编程来解决问题，而不是允许通过从数据中学习来发现解决问题的策略。在相当长的一段时间里，许多专家认为，人工智能可以通过手工制作一套足够大的明确规则来操纵知识和做出决策。
这种方法被称为“象征性人工智能”，从20世纪50年代到80年代末，它是人工智能的主导范式[12]
## 1.1.2 机器学习：与传统编程有何不同
机器学习，作为人工智能的一个子领域，有别于symbolic AI，它源于一个问题：计算机能否超越程序员让程序来执行工作，并是否可以独立学习来执行特定的任务？如你所见，机器学习的方法与symbolic AI的方法有着根本的不同。symbolic AI依赖于硬编码知识和规则，而机器学习则试图避免。所以，如果一台机器没有被明确指示如何执行任务，它将如何学习如何执行任务？答案是从数据中的例子中学习。
###### 图1.2 比较经典编程范式和机器学习范式。 

<img :src="$withBase('/introduction/1.2.png')" alt="figure2"/>
 
这为新的编程范式打开了大门。举一个机器学习范例，假设您正在开发一个处理用户上传照片的web应用程序。你想在应用程序中实现一个功能便是将照片自动分类为包含人脸和不包含人脸的照片。为此，您需要创建一个程序，以便在给定任何输入图像（由像素数组构成）的情况下输出二进制有人脸/无人脸答案。我们人类可以在瞬间完成这项任务：我们的大脑和生活经验赋予我们这样做的能力。然而，用编程语言（人类与计算机交流的唯一实用方法）写一套明确的规则，来准确地确定图像是否包含人脸，是相当困难的。 你可以花上几天的时间仔细研究像素的RGB值来编写算术运算的代码，以便检测出像脸、眼睛和嘴巴的椭圆轮廓，并得出关于轮廓之间几何关系的大致规则，但很快你就会意识到，这种努力充满了难以证明的逻辑和参数的多重选择。更重要的是，它真的很难做好[13]！当你面对现实生活中可能出现的各种各样的变化时，任何你想到的启发都有可能落空，比如脸的大小、形状和细节、面部表情、发型、肤色、方向、是否存在部分遮挡、眼镜、照明条件，背景中的物体等。在机器学习范式中，你认识到为这样的任务手工制定一套规则是徒劳的。由此，你可以去找一组图像，有人脸的和没有人脸的。然后为每个人输入所需的（即正确的）有人脸或无人脸的答案。这些答案被称为标签。这是一个更容易处理的（事实上，是很琐碎的）任务。如果有很多图像，可能需要一些时间来标记所有图像，但是标记任务可以在几个人之间进行，并行进行。一旦标记了图像，就可以应用机器学习，让机器自己发现规则集。如果您使用正确的机器学习技术，您将得到一套经过训练的规则，能够以大于99%的精度识别出有人脸或无人脸任务，远远优于手工标注。

从上面的例子可以看出，机器学习是自动发现解决复杂问题规则的过程。这种自动化适用于像人脸检测这样的问题，在这些问题中，人们直观地知道规则，并且可以轻松地标记数据。对于其他一些问题，规则是不直观的。例如，给定网页和广告内容以及如时间和位置等其他信息，预测用户是否将单击网页中显示的广告的问题。一般来说，没有人可以准确的预测出这些问题。这一数据结果也会随着时间和新内容和新广告的出现而改变，然而这些数据可以从广告服务器的日志中获得，并可以作为有标签的训练数据。仅数据和标签的可用性就使得机器学习非常适合解决这样的问题。

###### 图1.3 比图1.2更详细的机器学习范例图。机器学习的工作流程包括两个阶段：训练和推理。训练是机器自动发现将数据转换为答案的规则的过程。所学习的规则被封装在一个经过训练的“模型”中，这是训练阶段的成果，也是构成推理阶段的基础。推断是指使用模型获取新数据的答案。
<img :src="$withBase('/introduction/1.3.png')" alt="figure1.3"/>
 
在图1.3中，我们将更仔细地研究机器学习中涉及的步骤，有两个重要阶段。首先是训练阶段，这个阶段需要数据和结果，统称为训练数据。每对输入数据和期望的答案都称为一个示例。有了这些示例，训练中便会自动地发现规则。尽管如此，它们也不是完全从零开始发现的。换句话说，机器学习算法在制定规则方面没有创造性。人类工程师在训练开始时便会提供有关规则的蓝图，这一蓝图会封装在模型中。模型为机器可能学习的规则形成了一个假设空间。没有这个假设空间，就会有一个完全不受约束的无限可能的规则搜索空间，这不利于在有限的时间内找到好的规则。下面我们将详细描述什么样的模型可用，以及如何根据当前的问题选择最佳的模型。在如今的深度学习中，神经网络由多少层组成，它们是什么类型的层，以及它们是如何连接在一起的，每一种模型都各不相同。

利用训练数据和模型结构，封装在训练模型中的训练过程便会生成学习到的规则。这个过程会通过改变（或调整）模型结构使得模型的输出越来越接近期望的输出。训练阶段可以在毫秒和几天之间进行，取决于1）训练数据的量，2）模型体系结构的复杂性和3）硬件的速度。这种类型的机器学习，即使用标记的例子逐步减少模型输出中的错误，被称为监督学习[14]。本书中提及的大部分的深度学习都是监督学习。

一旦我们有了训练模型，我们就可以将学习到的规则应用到新数据上，即训练过程从未见过的数据。这是第二阶段，即推理阶段。推理阶段的计算强度比训练阶段低，因为1）推理通常一次发生在一个输入（例如，一幅图像）上，而训练需要遍历所有的训练数据；2）在推理过程中，不需要修改模型。

#### 数据的表现形式
机器学习就是从数据中学习。但到底学到了什么？答案是：一种有效转换数据的方法，换句话说，如何将数据的旧表示形式更改为新表示形式，从而使我们能够解决手头的问题。

在我们进一步讨论之前，什么是表现形式？它的核心是一种查看数据的方式。相同的数据使用不同的方式处理，会得到不同的表现。例如，彩色图像可以具有RGB（红绿蓝）或HSV（色调饱和度值）编码。“编码”和“表示形式” 的意思基本上是一样的，可以互换使用。当以这两种不同格式编码时，表示像素的数值是完全不同的，即使它们是针对同一图像的。不同的表示对于解决不同的问题是有用的。例如，为了找到图像的所有红色部分，RGB表示更有用；但是为了找到同一图像的颜色饱和部分，HSV表示更有用。这就是机器学习的本质：找到适当的转换，将输入数据的旧表示转换为新的表示，这种转换能够解决手头的特定任务，例如检测图像中汽车的位置或确定图像是否包含猫和狗。

一个直观的例子，我们在一个平面上有一组白点和一些黑点（图1.4）。假设我们想开发一种算法，可以获取一个点的二维（x，y）坐标，并预测该点是黑色还是白色。在这种情况下，

-	 输入数据是点的二维笛卡尔坐标（x和y）。

-	输出的是点的预测颜色（无论是黑色还是白色）。
###### 图1.4 机器学习所涉及的表示转换的一个示例：由平面上的黑白点组成的数据集的原始表示（面板A）。两个连续的转换步骤将原始表示转换为更适合颜色分类任务的表示（面板B和C）。
 
<img :src="$withBase('/introduction/1.4.png')" alt="figure1.4"/>
 
数据显示了图1.4的面板a中的一个模式。给定x和y坐标，机器如何决定点的颜色？它不能简单地将x与数字进行比较，因为白点的x坐标范围与黑点的x坐标范围重叠！相似的，也不能使用y坐标。因此，可以看出，对于黑白分类任务来说，点的原始表示不是一个好的表示。

我们所需要的新表示方法是可以以更直接的方式来分开两种颜色。由此，我们将原始的笛卡尔x-y的表示方法转换为极坐标系表示方法。新的表示方法：X轴和连接原点与点的线形成的角度（参见图1.4中的A面板的例子）以及图B中纵坐标的半径：点与原点的距离。在这个转换之后，我们得到了同一组数据的新表示，如图1.4的面板B所示。这种表示更适合我们的任务，因为黑白点的角度值现在完全不重叠。然而，这种新的表示仍然不是一个理想的表示，因为黑白颜色分类不能与阈值（如0）进行简单的比较。

幸运的是，我们可以应用第二个转换来实现目标。这个转换基于简单的公式：（角度的绝对值）-135度。

如面板C所示，得到一维表示方法。与面板B中的表示相比，它丢弃了关于点到原点距离的无关信息。这是一个完美的表现，因为它允许一个完全直接的决策过程：如果value<0,表示白色；相反，必须表示黑色。

在示例中，我们手动定义了数据表示的两步转换。如果取而代之的使用不同可能的转换形式来进行自动搜索并对正确分类点数进行百分比的反馈，那么便是进行机器学习。解决真正的机器学习问题所涉及的转换步骤的数量通常远大于两个，特别是在深度学习中，这个数量可以达到数百个。而且，与这个简单的例子相比，在实际机器学习中看到的表示转换的类型可能要复杂得多。正在进行的深度学习研究其实在不断发现更复杂和更强大的转换方式。图1.4中的例子更好的解释了机器学习的本质。这适用于所有的机器学习算法，包括神经网络、决策树、核方法等。

## 1.1.3 神经网络与深度学习

神经网络是机器学习的一个分支，其中数据表示的转换是由一个系统完成的，该系统的结构松散型是受到人和动物大脑中神经元连接方式的启发。大脑中的神经元是如何相互连接的？不同物种的大脑区域都不尽相同，但神经元连接的部分通常是层组织。哺乳动物大脑的许多部分是以分层的方式组织的。例如视网膜、大脑皮层和小脑皮层。视网膜是一层薄薄的神经组织，位于眼睛后部，负责视觉处理的早期阶段。它由多层组成，在每一层中，神经元基本上是同一类型的。层与层之间，有不同类型的神经元。现代神经解剖学先驱圣地亚哥·拉蒙·卡哈尔（Santiago Ramón y Cajal）的精美显微镜图完美地说明了这些模式（图1.5）。不同层的神经元以一种基本有序的方式连接到其他层。例如，一个层可以直接连接到它之前和之后的层，但不能连接到更远的层。也有例外，有些层确实连接到与它们不直接相邻的层。但视网膜的一般解剖结构表明，信息从一层到下一层基本上是直接流动的[15]。

###### 图1.5生物神经系统的层次结构。这些是圣地亚哥·拉蒙·卡哈尔（1852-1934）的绘画，他是现代神经解剖学的先驱。A组：小脑皮质的层组织。B组：视网膜神经元层。来源：https://www.sciencedirect.com/science/article/abs/pii/S0361923006002334https://nei.nih.gov/intramural/lrcmb/LRCMB_image

<img :src="$withBase('/introduction/1.5.png')" alt="figure1.5"/>
 
至少在表面上，这种模式有点类似于人工神经网络的一般组织（在当今的计算世界中，简单地称为神经网络，几乎不存在混淆的风险），在这种组织中，数据被分为多个可分离的阶段进行处理，恰当地命名为层。这些层通常堆叠在一起，只有相邻层之间才有连接。图1.6显示了一个简单的（人工）神经网络，有四层。输入数据（在本例中是图像）进入第一层（在图的左侧），然后从一层到下一层依次流动。每一层对于数据进行转换得到新的表现方式。随着数据在各层之间的流动，表示方法与原始方法越来越不同，并且越来越接近神经网络的目标，即在输入图像上标注的正确标签。最后一层（在图的右侧）得到神经网络的最终输出，这是图像分类任务的结果。

神经网络层类似于数学函数，它是从输入值到输出值的映射。然而，神经网络层不同于纯数学函数，因为它们通常是有状态的。换句话说，它们拥有内部记忆。此记忆便是权重。什么是“权重”？它们只是属于层的一组数值，并控制层如何将每个输入表示转换为输出表示的细节。例如，常用的“密集”层通过将输入数据与矩阵相乘并将向量添加到矩阵相乘的结果中来变换输入数据。矩阵和向量是稠密层的权重。当一个神经网络通过在训练数据中进行训练时，权值会有系统地改变，以称为损失函数的某个值的方式来表示，我们将在第2章和第3章中使用具体的例子详细介绍这一点。

###### 图1.6 分层组织的神经网络示意图。该神经网络对手写数字图像进行分类。在层间，有原始数据暂时表现的方式。经许可，转载自Chollet（2017）“与蟒蛇深入学习”。

<img :src="$withBase('/introduction/1.6.png')" alt="figure1.6"/>
 
即使神经网络的灵感来源于大脑，但我们应该注意不要过于人性化。神经网络的目的不是研究或模拟大脑的工作方式。其为神经科学的领域，是一门独立的学科.。神经网络是指通过从数据中学习，使机器能够执行有趣的实际任务。事实上，一些神经网络在结构和功能上都与生物大脑的某些部分相似[16]。不知这是否超出了本书的范围。无论如何，相似之处不应被忽略。重要的是，没有证据表明大脑通过任何形式的梯度下降来学习，梯度下降是神经网络训练的主要方式（下一章将介绍）。神经网络中许多重要的技术在深度学习革命中被发明并应用，并不是因为它们得到了神经科学的支持，而是因为它们帮助神经网络更好更快地解决了实际的学习任务。
既然你知道什么是神经网络，我们就可以告诉你什么是深度学习。深度学习便是深度神经网络的延伸和应用，简单来说，深度神经网络便是拥有多层（从数十层到数百层）的神经网络。在这里，“深”一词代表了大量连续表示层的概念。数据模型的层数便是模型的深度。该领域的其他适当名称可以是“layered representation learning”和“hierarchical representation learning”。如今的深度学习通常涉及数十或数百个连续的表示层，它们都是从训练数据中自动学习的。机器学习的某些方法往往只关注学习数据的一到两层；因此，它们有时被称为浅层学习。

人们错误地认为，深度学习中的“深度”是指对数据的任何一种深度理解，即理解“自由不是自由”等句子背后的含义，或品味M.C.埃舍尔绘画中的矛盾和自我矛盾。对于人工智能研究人员来说，这个“深”仍然是难以捉摸[17]。在未来，深度学习可能会使我们更接近这种深度，但这肯定比向神经网络添加层更难量化和实现。

:::tip 信息框1.1

不仅仅是神经网络：其他流行的机器学习技术。我们直接从图1.1中的Venn图的“机器学习”圈到“神经网络”圈。这里我们需要简单介绍一下非神经网络的机器学习技术，这不仅是因为这样做会让我们具备更好的知识基础，而且您可能会看到其在代码中的一些技术。   
朴素贝叶斯分类器是机器学习的最早形式之一。简单地说，贝叶斯定理是关于如何估计一个事件发生的概率，假设1）事件发生的可能性的先验结果，2）与事件有关的因素（称为特征）。这个定理根据明显的因素，通过选择概率最大（似然最大估计？）的类别，将观测数据点分为许多已知的类别之一。朴素贝叶斯是用于不同相互独立特征下的假设（一个强大的假设，因此得名）。

Logistic回归（或logreg）也是一种分类技术。由于它的简单和多用途的性质，仍然很受欢迎，而且通常是数据科学家首先使用的了解手头分类任务的技术。

Kernel方法，支持向量机（SVM）中是最著名的例子，解决二进制（即两类）分类问题，通过映射原始数据到高维空间，并找到一个最大化距离（称为“边缘”）在两类例子之间的转换。

决策树是一种类似流程图的结构，允许您对输入数据点进行分类或预测给定输入的输出值。在流程图的每个步骤中，您都会回答一个简单的是/否问题，例如“功能X是否大于某个阈值？”。根据答案是“是”还是“否”，您将进入下两个可能性步骤之一，这又是另一个“是/否”问题，以此类推。一旦你到达流程图的末尾，你将得到最终的答案。因此，决策树很容易形象的表示和解释。

随机森林和梯度增强是通过形成大量个性化、独特的决策树的集合来提高决策树的准确性。集成，也称为集成学习，是训练单个机器学习模型的集合（即集成）并在推理过程中使用其输出的集合的技术。如今，梯度增强可能是处理非感知数据（如信用卡欺诈检测）的最佳算法之一，即使不是最佳算法。除了深度学习之外，它也是数据科学竞赛中最常用的技术之一，例如Kaggle上的竞赛。
:::


### 神经网络的兴起、衰落和兴起及其背后的原因
神经网络的核心思想早在20世纪50年代就形成了，训练神经网络的关键技术，包括反向传播技术，都是在80年代发明的，但是在1980到2020很长一段时间里，神经网络几乎完全被研究界所规避。部分原因是支持向量机等方法的流行，部分原因是缺乏训练深层（多层次）神经网络的能力。但在2010年左右，仍在研究神经网络的一些人开始取得重要突破：多伦多大学的杰弗里·辛顿、蒙特利尔大学的约书亚·本吉奥、纽约大学的亚恩·莱肯以及瑞士IDSIA的研究人员。这些小组取得了重要的里程碑，包括在图形处理单元（GPU）上首次实现了深度神经网络，并在ImageNet计算机视觉挑战中将错误率从大约25%降低到不到5%。

自2012年以来，卷积神经网络（convnets）已成为所有计算机视觉任务的通用算法；另外，它们也可以处理所有感知任务。非计算机视觉感知任务的例子包括语音识别。在2015年和2016年的大型计算机视觉会议上，几乎不可能找到不涉及convnets的演讲。同时，深度学习也在许多其他类型的问题中找到了应用，比如自然语言处理。它在广泛的应用中完全取代了支持向量机和决策树。几年来，欧洲核子研究组织（CERN）使用基于决策树的方法来分析大型强子对撞机（LHC）ATLAS探测器的粒子数据；但是CERN最终转向了深层神经网络，因为它们具有更高的性能，并且易于在大型数据集上进行训练。

深度学习为什么能够在多种机器学习算法中脱颖而出呢？（信息框1.1是一些流行的机器学习技术，但这些技术不是深度神经网络。）深度学习之所以迅速发展，主要原因是它在许多问题上提供了更好的性能。但这不是唯一的原因。深度学习也使问题的解决变得更加容易，因为它使得过去机器学习工作流中最关键和最困难的一步自动化获得：特征工程。

之前的机器学习技术—浅度学习--仅涉及将输入数据转换为一个或两个连续的表示空间，通过简单的转换，如高维非线性回归（kernel方法）或决策树。但复杂问题所要求的精细表示一般不能用这种技术来实现。因此，工程师必须竭尽全力使最初输入的数据更易于处理，他们必须为数据设计更好的表示层。这便是特征工程。另一方面，深度学习使这一步自动化：通过深度学习，你可以一次性学习所有功能，而不必自己设计它们。这大大简化了机器学习工作流程，通常用一个简单的端到端深度学习模型取代复杂的多级管道。通过自动化的特征工程，深度学习使机器学习更省力、更健壮。

深度学习如何从数据中学习有两个基本特征：增量的、逐层的、越来越复杂的表示方式，以及遵循上一层和下一层的需求，每一层都将被更新，这些中间增量表示是共同学习的。这两个特性使得深度学习比以前的机器学习方法更为成功。
## 1.1.4 本书为什么是深度学习？为什么是现在？
如果早在20世纪80年代，神经网络的基本思想和核心技术就已经存在，为什么只有2012年后才开始发生深度学习革命？总言之，推动机器学习进步的技术力量有三：
- 硬件
- 数据集和基准
- 算法提升

让我们逐一考察这些因素。
### 1.1.4.1硬件
深度学习是一门以实验结果而非理论为指导的工程科学。只有当有合适的硬件来尝试新的想法（或者像通常的情况那样升级旧的想法）时，算法的进步才成为可能。在计算机视觉或语音识别中使用的典型深度学习模型需要的计算能力比你的笔记本电脑所能提供的计算能力大几个数量级。在21世纪初至今，像NVIDIA和AMD这样的公司持续投资数十亿美元来开发快速、大规模并行芯片（图形处理单元，或说GPU），为越来越逼真的视频游戏图形提供廉价、单用途的超级计算机，设计用于实时在屏幕上呈现复杂的3D场景。2007年，NVIDIA推出了CUDA（Compute Unified Device Architecture，简称“计算统一设备体系结构”），这是一款通用的GPU编程接口，这项投资使科学界受益匪浅。从物理建模开始，少量的GPU开始在各种高度并行化的应用中取代大量的CPU集群。深度神经网络，主要由许多矩阵乘法和加法组成，也具有高度的并行性。2011年前后，一些研究人员开始编写CUDA的神经网络实现方式，Dan Ciresan和Alex Krizhevsky是其中的第一批研究人员。今天，当训练深层神经网络时，一个高端的GPU可以提供比一个典型的CPU能力高数百倍的并行计算能力。如果没有现代GPU强大计算能力，就不可能训练出许多最先进的深层神经网络。
### 1.1.4.2 数据集和基准
如果硬件和算法是深度学习革命的蒸汽机，那么数据就是它的煤：为我们的智能机器提供动力的原材料，没有它，什么都不可能。在数据方面，除了过去20年存储硬件的指数级发展（遵循摩尔定律），互联网的兴起改变了游戏规则，使用于机器学习的非常大的数据集的收集和分发成为可能。如今，大公司使用的是图像数据集、视频数据集和自然语言数据集，如果没有互联网，这些数据集是无法收集的。例如，用户在Flickr上生成的图像标签已经成为计算机视觉数据的宝库。YouTube视频也是如此。维基百科是自然语言处理的关键数据集。

如果说有一个数据集是推动深度学习兴起的催化剂，那就是ImageNet数据集，它由140万张手工标注了1000个图像类别的图像组成。但使ImageNet与众不同的不仅仅是它的庞大规模，还有与之相关的年度比赛。正如ImageNet和Kaggle自2010年以来，公开竞争是激励研究人员和工程师们奋力拼搏的绝佳方式。拥有共同的基准，研究人员竞相超越，极大地帮助了最近兴起的深度学习。

### 1.1.4.3算法
除了硬件和数据，直到21世纪末，我们还缺少一种可靠的方法来训练非常深的神经网络。所以神经网络仍然相对浅层，仅使用一层或两层表示；因此，它们无法与更精细的浅层方法（如支持向量机和随机森林）抗衡。关键的问题是梯度传递会通过层层之间的堆叠。用于训练神经网络的反馈信号会随着层数的增加而逐渐消失。
这在2009-2010年左右发生了变化，出现了一些简单但重要的算法提升，允许更好的梯度传递：
- 更好的神经网络层激活功能（例如，校正线性单元或“ReLU”）。
- 更好的权重初始化方案（例如Glorot初始化）
- 更好的优化方案（例如RMSProp和ADAM优化器）

只有当这些改进开始允许10层或更多层的训练模型时，深度学习才开始发光。最后，在2014年、2015年和2016年，人们发现了更先进的方法来帮助梯度传递，如批量规范化、残差连接和可分离反褶积。今天我们可以训练几千层的模型。











