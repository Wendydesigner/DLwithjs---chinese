(window.webpackJsonp=window.webpackJsonp||[]).push([[35],{218:function(t,s,l){"use strict";l.r(s);var a=l(0),e=Object(a.a)({},(function(){var t=this,s=t.$createElement,l=t._self._c||s;return l("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[l("h1",{attrs:{id:"强化学习基础"}},[l("a",{staticClass:"header-anchor",attrs:{href:"#强化学习基础"}},[t._v("#")]),t._v(" 强化学习基础")]),t._v(" "),l("div",{staticClass:"tip custom-block"},[l("p",{staticClass:"custom-block-title"},[t._v("内容包括：")]),t._v(" "),l("ul",[l("li",[t._v("强化学习（RL）与前几章中介绍的监督学习有何不同")]),t._v(" "),l("li",[t._v("强化学习的基本范式：代理，环境，行为和奖励，以及它们之间的相互作用")]),t._v(" "),l("li",[t._v("解决 RL 问题的两种主要方法背后的一般思想：基于策略的方法和基于价值的方法")]),t._v(" "),l("li",[t._v("以示例为基础的基于策略的 RL 算法：使用策略梯度（PG）方法解决购物车问题")]),t._v(" "),l("li",[t._v("通过基于 Q 值的 RL 算法为例：使用深度 Q 网络（DQN）解决蛇游戏。")])])])])}),[],!1,null,null,null);s.default=e.exports}}]);